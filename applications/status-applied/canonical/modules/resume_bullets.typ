// Bullet points for work experience (customizable per job)

// Technical skills section (add for this application)
#let technical_skills = (
  "MLOps & Analytics: Kubeflow, MLflow, Feast, Docker, Kubernetes, DuckDB, Python (10+ years), ML engineering",
  "Cloud Platforms: AWS, GCP, Azure - deployment, scaling, and optimization of ML applications",
  "Operating Systems: Ubuntu Linux (10+ years of professional and personal use), container technologies",
  "Open Source: Active contributor to Python ML ecosystem, experience with distributed open source projects",
)

// URBN - Customized for Canonical's MLOps Manager position
#let urbn_bullets = (
  "Engineering Manager for a team of 6 ML engineers, implementing MLOps best practices and establishing code review processes that improved code quality and knowledge sharing.",
  "Led migration from Airflow to Flyte on Kubernetes, reducing technical debt and improving workflow orchestration for ML pipelines while mentoring team members through the transition.",
  "Redesigned MLflow architecture on Ubuntu-based infrastructure, enhancing ML experiment tracking and improving model reproducibility and team collaboration across distributed teams.",
  "Established testing culture by implementing Python-based testing frameworks (Pandera, Pydantic, Pytest) for previously untested ML pipelines and infrastructure.",
  "Optimized ETL pipeline performance by transitioning from pandas to DuckDB on Linux servers, resulting in 40% improved processing efficiency for analytics workloads.",
)

// Pepsico Head ML Engineering - Customized for Canonical
#let pepsico_head_bullets = (
  "Engineering Manager for a multidisciplinary team of 10 ML engineers and data scientists, implementing performance reviews and mentorship programs that increased team productivity by 200%.",
  "Established distributed team collaboration practices for remote engineers across 4 time zones, creating documentation standards and asynchronous communication protocols.",
  "Implemented Kubeflow and MLflow on Ubuntu-based infrastructure for model management, reducing model deployment time by 75% and enabling systematic ML experimentation.",
  "Led code review processes and technical design discussions, elevating software quality standards and reducing production incidents by 60% through improved testing.",
  "Re-architected the MLOps lifecycle on containerized infrastructure (Docker, Kubernetes), decreasing model deployment time and increasing operational efficiency by 200%.",
)

// Pepsico Principal Data Scientist - Customized for Canonical
#let pepsico_principal_bullets = (
  "Provided technical leadership for ML engineering team, mentoring 5 junior engineers while establishing Python development standards and code review processes.",
  "Architected production ML pipeline infrastructure using Kubeflow on Kubernetes, standardizing processes from data ingestion to modeling, with reductions in time-to-delivery by 50%.",
  "Implemented MLflow experiment tracking and model registry on Ubuntu servers, enabling reproducible experiments and simplifying model deployment to production.",
  "Built containerized ML applications using Docker and Kubernetes, ensuring consistent development and deployment environments for Python-based ML services.",
  "Collaborated with open source communities to implement best practices for ML model governance and deployment, contributing improvements to project documentation.",
  "Leveraged cloud platforms (AWS, GCP) for scalable ML infrastructure, optimizing compute resources and reducing training costs by over $10k per month.",
  "Standardized Python development practices across ML engineering team, implementing linting, type checking, and CI/CD pipelines to ensure code quality.",
  "Designed analytics dashboards for ML performance monitoring, enabling data-driven decisions about model retraining and feature engineering.",
)

// Penn Interactive - Customized for Canonical
#let penn_interactive_bullets = (
  "Founded the ML engineering function on Linux-based infrastructure, bootstrapping a team of Python developers to pioneer predictive analytics applications.",
  "Implemented containerized ML pipeline architecture with Docker and Kubernetes, enabling consistent deployments across development and production environments.",
  "Developed Python-based ML algorithm delivery infrastructure on Ubuntu servers, significantly shortening development cycles and improving reliability.",
  "Built distributed ML systems using open source technologies, ensuring scalability through containerization and infrastructure-as-code practices.",
  "Established code review and documentation standards for the ML engineering team, improving software quality and knowledge sharing.",
  "Created analytics dashboards for real-time performance monitoring, replacing batch analytics with continuous intelligence for business stakeholders.",
)

// Heavywater - Customized for Canonical
#let heavywater_bullets = (
  "Implemented Python-based document classification services on Ubuntu Linux servers, achieving 96% accuracy for financial document processing.",
  "Deployed machine learning models to production using containerization (Docker) for consistent runtime environments across development and production.",
  "Collaborated in distributed team environment using open source methodologies, implementing documentation standards and code review processes.",
)

// Education bullets - Customized to emphasize academic performance
#let temple_bullets = (
  "Graduated with distinction (3.9 GPA), with coursework in statistical machine learning, Python programming, and analytical methods for large datasets.",
)

#let lehigh_bullets = (
  "Graduated magna cum laude (3.8 GPA), with coursework in programming, statistics, and mathematical modeling.",
)

// Project bullets - Customized to highlight open source
#let pocketsize_bullets = (
  "Co-founder and CTO of Pocket Size Fund, an open source quantitative hedge fund built with Python, MLflow, and containerized infrastructure on Ubuntu Linux.",
)