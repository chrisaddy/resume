// Bullet points for work experience (customizable per job)

// URBN
#let urbn_bullets = (
  "Implemented comprehensive A/B testing framework for recommendation systems, enabling data-driven evaluation of user engagement metrics and systematic fine-tuning of language models.",
  "Redesigned MLflow architecture for tracking language model experiments, improving reproducibility of fine-tuning outcomes and facilitating team collaboration on model iterations.",
  "Established rigorous testing methodologies for ML pipelines using Pandera and Pydantic, ensuring robust information retrieval systems and quality evaluation frameworks.",
  "Optimized ETL pipeline performance for processing large text datasets by transitioning from pandas to DuckDB, significantly improving efficiency for language model training.",
  "Collaborated with cross-functional teams to implement production-grade large language model systems with robust evaluation and deployment workflows.",
)

// Pepsico Head ML Engineering
#let pepsico_head_bullets = (
  "Founded the Generative AI Lab, leading a team of 8 engineers to pioneer LLM fine-tuning approaches including RLHF and LoRA techniques, resulting in significant improvements to content generation quality.",
  "Orchestrated a multidisciplinary team of machine learning engineers and data scientists to build scalable information retrieval systems, achieving a 200% leap in data science productivity.",
  "Implemented vector database technology for efficient knowledge extraction and retrieval, expanding content generation capabilities and improving search relevance by 45%.",
  "Fueled an 8% revenue growth by devising and integrating transformer-based recommendation models with robust A/B testing frameworks for continuous improvement.",
  "Re-architected the ML infrastructure to support large language model experimentation, reducing model fine-tuning time by 60% and enabling rapid iteration on novel approaches.",
)

// Pepsico Principal Data Scientist
#let pepsico_principal_bullets = (
  "Architected robust ML pipeline infrastructure via PyTorch and KubeFlow, which standardized and streamlined processes from language data ingestion to model fine-tuning, reducing time-to-delivery by 50%.",
  "Implemented agentic approaches to information retrieval, combining knowledge graph technology with language models to enhance content generation and fact verification.",
  "Developed transformer-based natural language systems that advanced content personalization, leveraging quantitative A/B testing to rapidly adapt models to user preferences.",
  "Streamlined language model fine-tuning workflows using DPO (Direct Preference Optimization), enhancing model alignment with user expectations and cutting costs by over $10k per month.",
  "Right-sized distributed training for large language models, reducing fine-tuning times for transformers by 50%, resulting in a 150% increase in model iteration efficiency.",
  "Led the development of content quality evaluation frameworks, partnering with data scientists to enhance engagement metrics and establish quantitative performance benchmarks.",
)

// Penn Interactive
#let penn_interactive_bullets = (
  "Launched an advanced recommender system with BERT-based language modeling to personalize app experiences, achieving 30% improvement in content engagement through transformer-based approaches.",
  "Developed search index architecture for dynamic content retrieval, significantly improving user experiences and enabling contextual content recommendations across the platform.",
  "Implemented Bayesian A/B testing framework for evaluating language model outputs, elevating trust in algorithmic content decisions and decreasing evaluation times by 50%.",
  "Founded the ML engineering function, bootstrapping a team to pioneer transformer-based language applications, resulting in a successful launch with measurable improvements in user engagement.",
  "Created production ML systems with robust evaluation metrics, enabling seamless transition from research to deployment while maintaining content quality and consistency.",
  "Established real-time content quality dashboards using engagement metrics, replacing batch analytics with continuous evaluation for language model fine-tuning.",
)

// Heavywater
#let heavywater_bullets = (
  "Implemented transformer-based NER and text extraction systems for critical information retrieval from complex documents, achieving 96% accuracy in automated extraction.",
  "Designed knowledge graph representation of financial document structures, significantly improving classification accuracy across 300+ document types through advanced information modeling.",
  "Developed document understanding pipelines incorporating transformer models for text classification, boundary detection, and entity extraction, increasing processing efficiency by 10x.",
  "Created vector database search capabilities to facilitate document retrieval based on semantic similarity, enhancing the system's ability to organize and process complex information.",
  "Implemented serverless data pipelines for streamlined collection of training data, enabling continuous model fine-tuning and improvement of information extraction accuracy.",
)

// Education bullets
#let temple_bullets = (
  "Ph.D. research in deep learning and statistical machine learning with focus on language models, neural network architectures, and information retrieval systems.",
  "Published research on quantitative evaluation methodologies for machine learning applications, focusing on metrics-driven model improvement techniques.",
)

#let lehigh_bullets = (
  "Advanced studies in statistical foundations of machine learning, multivariate analysis, and computational methods for large-scale data processing.",
)

// Project bullets
#let pocketsize_bullets = (
  "Co-founder and CTO of Pocket Size Fund, an open source quantitative hedge fund leveraging natural language processing for financial sentiment analysis and market prediction models.",
)