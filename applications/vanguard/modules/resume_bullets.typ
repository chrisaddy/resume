// Bullet points for work experience (customizable per job)

// URBN
#let urbn_bullets = (
  "Led migration from Airflow to Flyte, reducing technical debt and improving workflow orchestration for ML pipelines in production environments.",
  "Redesigned MLflow architecture and implemented model monitoring systems to ensure stable performance of ML models in production.",
  "Established data quality standards by implementing Pandera, Pydantic, and Cucumber tests for previously untested ML pipelines and infrastructure.",
  "Optimized ETL pipeline performance by transitioning from pandas to DuckDB, resulting in improved data processing efficiency for model development.",
  "Collaborated with data science teams to implement ML model development lifecycle practices and accelerate model deployment to production.",
)

// Pepsico Head ML Engineering
#let pepsico_head_bullets = (
  "Orchestrated a multidisciplinary team to design and develop PySpark-based data pipelines in a distributed computing environment, achieving a 200% leap in data science productivity.",
  "Elevated ML adoption across the organization by implementing standardized data pipeline designs and documentation processes, expanding the number of analysts building data pipelines by 200%.",
  "Fueled an 8% revenue growth by developing and integrating ML models into production applications with robust monitoring and alert systems.",
  "Founded the Generative AI Lab, collaborating with stakeholders to understand business processes and develop hypotheses for AI applications in the ML ecosystem.",
  "Re-architected the ML model deployment lifecycle on AWS, reducing deployment time by 300% and implementing comprehensive model monitoring practices across the production environment.",
)

// Pepsico Principal Data Scientist
#let pepsico_principal_bullets = (
  "Implemented strategic PySpark-based ETL pipelines that reduced model development time to just three weeks, enabling quicker decisions on machine learning projects in production environments.",
  "Architected robust ML pipeline infrastructure using AWS services and distributed computing technologies, standardizing processes from data ingestion to modeling and production deployment.",
  "Performed detailed analysis of raw data sources for data quality and model development needs, ensuring high-quality data inputs for machine learning pipelines.",
  "Developed predictive ML systems integrated with production applications, working with stakeholders to translate business requirements into analytic approaches.",
  "Streamlined data science workflows through improved SQL and NoSQL database integration, cutting costs by over $10k per month and strengthening data pipeline efficiency.",
  "Optimized AWS cloud infrastructure including Glue ETL jobs, reducing model training and delivery times by 50% while maintaining rigorous model monitoring practices.",
  "Spearheaded efforts to unify data processes, standardizing pipeline designs and documenting design changes with data science teams to boost operational efficiency.",
  "Led model monitoring implementation for production ML systems, establishing alerts and processes that improved model reliability and performance in the production environment.",
)

// Penn Interactive
#let penn_interactive_bullets = (
  "Founded the ML engineering function, developing machine learning integrated software algorithms for predictive analytics in sports betting with Python and AWS services.",
  "Implemented robust data pipelines and SDLC processes for model production, significantly improving development workflow and software quality.",
  "Developed ML model pipelines with Python, SQL, and cloud technologies, significantly shortening development cycles and enabling rapid model deployment to production.",
  "Engaged with internal stakeholders to understand business processes and translated requirements into analytic approaches for personalized recommendation models.",
  "Created model monitoring systems using Python and AWS, ensuring reliable ML model performance and enabling quick response to performance issues.",
  "Established automated data discovery and ingestion processes for model development, streamlining data access for machine learning applications.",
)

// Heavywater
#let heavywater_bullets = (
  "Developed and implemented machine learning data pipelines for financial document processing, leveraging PySpark and distributed computing to handle large document volumes efficiently.",
  "Performed detailed analysis of raw data sources for data quality, applying business context to improve document classification models that achieved 96% accuracy in production.",
  "Implemented data model design changes and documented design decisions with data science teams, ensuring alignment between business requirements and technical implementation.",
)

// Education bullets
#let temple_bullets = (
  "Relevant coursework in statistical machine learning, survival analysis, structural equation modeling, and multivariate time-series modeling.",
)

#let lehigh_bullets = (
  "Relevant coursework in time-series forecasting and causal modeling.",
)

// Project bullets
#let pocketsize_bullets = (
  "Co-founder and CTO of Pocket Size Fund, an open source quantitative hedge fund.",
)