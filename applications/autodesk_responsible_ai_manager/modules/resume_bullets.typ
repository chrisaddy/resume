// Bullet points for work experience (customizable per job)

// URBN
#let urbn_bullets = (
  "Led research and implementation of safe, reliable AI workflow orchestration using Flyte, establishing robust governance frameworks for responsible AI systems that ensure transparency, accountability, and ethical model deployment.",
  "Conducted research on ML reproducibility and designed enhanced experiment tracking architecture using PyTorch and MLflow, implementing fairness metrics and bias detection to ensure responsible AI development.",
  "Established comprehensive safety testing and uncertainty quantification for AI systems using Pandera, Pydantic, and Cucumber frameworks, preventing potential model failures and mitigating algorithmic bias in production systems.",
  "Researched and implemented robust data validation techniques with DuckDB and PyTorch, ensuring fair and reliable data transformation while improving model alignment with ethical AI standards.",
  "Collaborated with cross-functional teams to research and implement responsible AI practices that balanced technical innovation with safety considerations, publishing internal guidelines on ethical AI deployment.",
)

// Pepsico Head ML Engineering
#let pepsico_head_bullets = (
  "Orchestrated research on responsible AI practices with a multidisciplinary team of ML engineers and data scientists, establishing ethical guidelines for AI development that balanced innovation with safety considerations.",
  "Founded and led the Generative AI Lab focused on responsible implementation of Large Language Models (LLMs) and diffusion models, developing robust safety measures and governance frameworks for AI deployment.",
  "Led research on model alignment and fairness in generative AI systems, implementing PyTorch-based evaluation frameworks that measured bias, toxicity, and hallucination rates to ensure responsible AI output.",
  "Published internal research on safe and reliable AI practices, presenting findings at quarterly technology forums and establishing cross-functional collaboration on ethical AI implementation.",
  "Re-architected the MLOps lifecycle with safety and responsibility as core principles, implementing extensive testing protocols for diffusion models and LLMs to identify potential ethical concerns before deployment.",
)

// Pepsico Principal Data Scientist
#let pepsico_principal_bullets = (
  "Developed responsible AI validation framework that enabled thorough safety and fairness testing during the model development cycle, reducing potential ethical issues while maintaining a three-week Proof-of-Concept timeline.",
  "Architected robust ML pipeline infrastructure via KubeFlow with built-in fairness assessments and uncertainty quantification, standardizing responsible AI development practices across the organization.",
  "Researched and implemented methods for transparent ML model evaluation, ensuring algorithmic fairness and providing uncertainty estimates that improved stakeholder trust in AI-powered decision systems.",
  "Developed predictive ML systems with PyTorch that incorporated responsible AI techniques, including model interpretability features and robustness to distribution shifts to ensure reliable performance.",
  "Led cross-functional collaboration on AI governance, establishing standard practices for model documentation, assumptions testing, and ethics reviews that ensured consistent responsible AI deployment.",
  "Implemented rigorous testing frameworks for ML systems, ensuring models met safety requirements and behavioral expectations before deployment while reducing potential biases in recommendations.",
  "Spearheaded research on data quality and fairness assessment tools, standardizing processes to identify and mitigate potential biases in training data before model development.",
  "Led the development of responsible recommendation systems using TensorFlow, implementing fairness constraints and algorithmic transparency to ensure ethical customer modeling while doubling marketing effectiveness.",
)

// Penn Interactive
#let penn_interactive_bullets = (
  "Established ethical AI principles for ML engineering function, leading research on responsible gambling detection algorithms that balanced business goals with player safety and regulatory compliance.",
  "Implemented comprehensive safety testing for AI systems, including simulated load testing and robustness verification, ensuring reliable performance under varied conditions while preventing potential failure modes.",
  "Researched and developed responsible ML algorithm delivery infrastructure with built-in fairness assessments and monitoring capabilities, ensuring ethical deployment of recommendation systems.",
  "Designed and implemented ethically-aware recommender system using TensorFlow and PyTorch, incorporating responsible AI practices including bias mitigation, transparency features, and appropriate content filtering.",
  "Conducted research on uncertainty quantification in ML systems using Bayesian A/B testing frameworks, improving decision reliability while providing transparency about confidence levels and potential risks.",
  "Established comprehensive monitoring for AI systems with DataDog, implementing real-time behavioral oversight to quickly identify and address potential ethical concerns in model outputs.",
)

// Heavywater
#let heavywater_bullets = (
  "Researched and implemented ethical AI practices for financial document classification, ensuring fairness and privacy compliance while classifying 300+ document types in mortgage packets with PyTorch-based models.",
  "Developed responsible AI system for document processing that maintained human oversight, implementing fairness metrics that ensured consistent 96% accuracy across diverse document types while providing uncertainty estimates for low-confidence predictions.",
  "Led research on safe NLP implementation for sensitive financial data extraction, ensuring privacy protection and regulatory compliance while developing models that maintained transparency and accountability in automated decisions.",
)

// Education bullets
#let temple_bullets = (
  "Focused research on statistical machine learning fairness metrics, uncertainty quantification methods, robust model evaluation techniques, and responsible AI implementation strategies.",
)

#let lehigh_bullets = (
  "Conducted research on causal inference methods and fairness considerations in predictive modeling, with emphasis on transparent and accountable algorithmic decision-making.",
)

// Project bullets
#let pocketsize_bullets = (
  "Co-founder and CTO of Pocket Size Fund, an open source quantitative hedge fund developing transparent and explainable AI systems for ethical algorithmic trading strategies.",
)