// Bullet points for work experience (customizable per job)

// URBN
#let urbn_bullets = (
  "Led migration from Airflow to Flyte, redesigning workflow orchestration architecture for ML pipelines and improving scalability for distributed model training workloads.",
  "Redesigned MLflow architecture and enhanced ML experiment tracking practices, enabling model versioning, reproducibility, and standardized model serving practices.",
  "Implemented high-performance system monitoring for ML infrastructure, identifying performance bottlenecks and optimizing resource utilization across machine learning workloads.",
  "Optimized data processing pipelines by transitioning from pandas to DuckDB, reducing memory usage by 60% and improving ETL processing speed by 45% for large-scale feature computation.",
  "Established comprehensive testing culture across ML infrastructure using Pandera, Pydantic, and Cucumber, ensuring reliability and stability of production machine learning services.",
)

// Pepsico Head ML Engineering
#let pepsico_head_bullets = (
  "Architected and scaled machine learning platform supporting 25+ production ML models, reducing model deployment time by 300% and improving operational efficiency by 200%.",
  "Led distributed system design for ML infrastructure serving multiple business units, enabling seamless model deployment across heterogeneous computing environments.",
  "Optimized distributed training infrastructure by implementing dynamic resource allocation, improving GPU utilization by 35% and reducing training costs by 40%.",
  "Designed high-performance feature store and model serving architecture, reducing latency by 55% for real-time inference workloads for consumer-facing applications.",
  "Directed platform development for the Generative AI Lab, building scalable infrastructure to support large language model fine-tuning and inference using Python and cloud-native technologies.",
)

// Pepsico Principal Data Scientist
#let pepsico_principal_bullets = (
  "Designed and implemented robust ML pipeline architecture using KubeFlow, standardizing end-to-end workflows from data ingestion to model deployment on distributed infrastructure.",
  "Optimized infrastructure for model training and deployment, reducing time-to-delivery by 50% through containerization and orchestration of machine learning workloads.",
  "Built high-performance distributed systems for data processing that scaled to handle 200+ GB of daily training data across multiple geographic regions.",
  "Right-sized AWS compute resources for ML workloads, reducing infrastructure costs by $10k monthly while improving model training throughput by 50%.",
  "Led the development of scalable model serving architecture for real-time inference, achieving sub-100ms latency for time-sensitive prediction services.",
  "Implemented scalable Python-based microservices architecture for ML feature computation and model serving, decreasing system complexity while improving maintainability.",
  "Spearheaded efforts to unify data processing infrastructure, standardizing distributed ETL pipelines and feature computation for cross-domain ML applications.",
  "Developed system architecture for marketing attribution models that could efficiently process billions of customer interactions with high throughput and reliability.",
)

// Penn Interactive
#let penn_interactive_bullets = (
  "Founded the ML engineering function, designing scalable infrastructure for distributed model training and serving that powered the platform's launch with 75k users.",
  "Architected high-performance RESTful services for ML model inference, achieving consistent sub-50ms response times even during peak load periods.",
  "Implemented distributed data processing infrastructure for feature computation, enabling real-time personalization across multiple application touchpoints.",
  "Developed scalable recommender system architecture with A/B testing framework, deploying models that handled millions of requests per day with 99.9% availability.",
  "Designed ML monitoring system using DataDog, providing real-time visibility into model performance, infrastructure utilization, and system reliability.",
  "Built and deployed NLP processing pipeline using BERT-based models, creating a scalable architecture that efficiently utilized GPU resources for inference.",
)

// Heavywater
#let heavywater_bullets = (
  "Architected ML system for classifying 300+ document types within mortgage packages, designing a scalable infrastructure that processed thousands of documents per hour.",
  "Implemented high-throughput document processing pipeline with distributed computing architecture, improving document review speeds by 10x through parallel processing.",
  "Built scalable NER system for financial document analysis, designing efficient text extraction services that reliably processed sensitive customer information.",
  "Developed serverless data pipelines for training data collection, creating a fault-tolerant system that automatically scaled based on processing demand.",
  "Optimized document classification algorithms, reducing inference latency by 65% while maintaining 96% accuracy across complex document types.",
)

// Education bullets
#let temple_bullets = (
  "Relevant coursework in statistical machine learning, distributed systems design, and computational optimization for large-scale data processing.",
)

#let lehigh_bullets = (
  "Relevant coursework in time-series forecasting and causal modeling.",
)

// Project bullets
#let pocketsize_bullets = (
  "Co-founder and CTO of Pocket Size Fund, an open source quantitative hedge fund, architecting scalable infrastructure for distributed financial modeling.",
)