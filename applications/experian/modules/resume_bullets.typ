// Bullet points for work experience (customized for Experian)

// URBN
#let urbn_bullets = (
  "Architected and implemented a cloud-native ML platform infrastructure supporting the entire AI/ML lifecycle, including data processing, feature engineering, model training, and serving workflows.",
  "Redesigned MLOps architecture, enabling distributed system deployment and cross-team adoption of platform components, improving model reproducibility and collaboration.",
  "Established observability and governance frameworks for ML pipelines using Pandera, Pydantic, and automated testing, ensuring data quality and model reliability.",
  "Optimized data-intensive processing pipelines by implementing modern data architecture patterns, resulting in improved efficiency and reduced resource consumption.",
  "Led cross-functional platform adoption initiatives, guiding engineering and data science teams in leveraging shared platform services and infrastructure.",
)

// Pepsico Head ML Engineering
#let pepsico_head_bullets = (
  "Provided architectural leadership for enterprise-wide data and AI platform capabilities, orchestrating platform components that supported the entire ML lifecycle across global business units.",
  "Drove platform adoption across the organization, expanding analyst utilization of data pipelines by 200% through solution architecture design and cross-team influence.",
  "Designed and implemented scalable, secure platform components for multi-tenant model serving, enabling an 8% revenue growth through AI-powered recommendation systems.",
  "Established Generative AI infrastructure, evaluating build vs. buy decisions for MLOps frameworks, vector stores, and LLM orchestration tools within the ML ecosystem.",
  "Re-architected distributed ML platform infrastructure, reducing model deployment time by 300% and implementing cloud-native design patterns for improved operational efficiency.",
)

// Pepsico Principal Data Scientist
#let pepsico_principal_bullets = (
  "Designed and implemented data-intensive platform components that reduced time-to-delivery for ML models by 50% through standardized infrastructure and reusable services.",
  "Architected robust ML platform infrastructure using KubeFlow, Docker, and Kubernetes, creating a distributed system for data processing and model serving pipelines.",
  "Implemented feature engineering and model training/serving components that accelerated proof-of-concept timelines to just three weeks, enabling rapid innovation cycles.",
  "Developed CI/CD pipelines for ML infrastructure using AWS and Terraform, ensuring reliable deployment and scaling of platform services.",
  "Optimized big data processing frameworks for predictive analytics workloads, leveraging cloud-native architecture to handle TB-scale datasets efficiently.",
  "Right-sized cloud infrastructure for distributed ML workloads, reducing model training times by 50% and implementing cost-efficient scaling for varying computational demands.",
  "Spearheaded platform standardization initiatives, unifying data processing, feature engineering, and model serving components to boost operational efficiency.",
  "Led cross-functional adoption of ML platform services, partnering with data scientists to enhance analytics capabilities and double marketing effectiveness.",
)

// Penn Interactive
#let penn_interactive_bullets = (
  "Founded the ML platform architecture function, designing foundational infrastructure components for predictive analytics that scaled to handle 75k users and $8M in transactions.",
  "Architected cloud-native ML infrastructure with comprehensive observability, enabling rigorous load testing and continuous platform improvements.",
  "Developed distributed system architecture for ML algorithm delivery, implementing scalable RESTful services that shortened development cycles and improved platform adoption.",
  "Designed and implemented feature engineering pipelines and model serving infrastructure for recommendation systems, incorporating BERT-based language models.",
  "Established data-intensive platform components for experimentation, implementing Bayesian testing frameworks that decreased decision times by 50%.",
  "Built real-time observability infrastructure for platform components, replacing batch analytics with continuous monitoring and performance insights.",
)

// Heavywater
#let heavywater_bullets = (
  "Architected data processing platform for financial document classification, implementing distributed systems to process 300+ document types within mortgage packets.",
  "Designed scalable, cloud-native infrastructure for document processing that increased throughput from 3-4 to 30-50 documents per hour through efficient data pipelines.",
  "Implemented feature engineering components for NER and text extraction from financial documents, improving model accuracy and platform performance.",
  "Developed serverless data pipeline architecture using infrastructure-as-code principles, creating reusable platform components for training data collection.",
)

// Education bullets
#let temple_bullets = (
  "Relevant coursework in distributed systems, cloud-native architecture, and data-intensive platforms for machine learning applications.",
)

#let lehigh_bullets = (
  "Relevant coursework in data engineering, statistical modeling, and system architecture design.",
)

// Project bullets
#let pocketsize_bullets = (
  "Co-founder and CTO of Pocket Size Fund, an open source quantitative hedge fund with distributed data processing architecture for financial analytics.",
)