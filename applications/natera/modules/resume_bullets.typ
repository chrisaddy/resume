// Bullet points for work experience (customizable per job)

// URBN
#let urbn_bullets = (
  "Led migration from Airflow to Flyte, establishing scalable workflow orchestration for complex ML pipelines with enhanced reproducibility and error handling",
  "Redesigned MLflow architecture for robust experiment tracking and model registry, improving model reproducibility and enabling seamless deployments across environments",
  "Architected containerized ML systems using Docker and Kubernetes, enabling consistent development environments and streamlined model deployment",
  "Established comprehensive testing frameworks for ML infrastructure using Pandera, Pydantic, and Cucumber, reducing production incidents by 40%",
  "Optimized data processing pipelines by transitioning from pandas to DuckDB, achieving 3x performance improvement for large-scale analytics workloads",
)

// Pepsico Head ML Engineering
#let pepsico_head_bullets = (
  "Led a diverse team of ML engineers and data scientists to build production-grade AI systems, increasing data science productivity by 200% and reducing ML pipeline development from months to days",
  "Founded the Generative AI Lab, leading a team of 8 engineers in developing agentic systems for complex business queries using LLMs, vector databases, and fine-tuned domain-specific models",
  "Redesigned MLOps infrastructure using Kubernetes and cloud-native technologies, reducing model deployment time by 75% and enabling automated model monitoring and retraining",
  "Championed implementation of standardized ML workflows across the organization, expanding the number of data scientists building production data pipelines by 200%",
  "Delivered 8% revenue growth by developing and deploying advanced recommendation systems integrated with business applications and core product features",
)

// Pepsico Principal Data Scientist
#let pepsico_principal_bullets = (
  "Architected enterprise-wide ML pipeline infrastructure using KubeFlow, standardizing processes from data ingestion to model deployment and reducing delivery time by 50%",
  "Designed and implemented scalable deep learning systems using PyTorch and TensorFlow for predictive analytics, deployed across AWS environments with automated CI/CD pipelines",
  "Established ML workflow best practices that reduced model development cycles from months to three weeks, enabling rapid iteration and experimentation",
  "Developed sophisticated statistical models for retail analytics and customer segmentation, generating actionable insights that drove strategic decision-making",
  "Optimized cloud infrastructure for ML workloads on AWS, reducing compute costs by \$10k monthly while improving model training performance",
  "Engineered robust data processing pipelines handling terabytes of structured and unstructured data with high reliability and fault tolerance",
  "Led cross-functional collaborations between data science, engineering, and business teams to deliver ML solutions aligned with strategic objectives",
  "Pioneered adoption of MLOps practices across the organization, enabling seamless model deployment, monitoring, and governance",
)

// Penn Interactive
#let penn_interactive_bullets = (
  "Founded and scaled the ML engineering function, building a team focused on developing production ML systems that powered predictive analytics across the platform",
  "Engineered scalable RESTful APIs for ML model serving, enabling real-time personalization and recommendations that improved user engagement by 35%",
  "Developed advanced NLP systems using BERT-based language models for text classification and entity extraction from unstructured data sources",
  "Implemented Bayesian experimental framework for rigorous A/B testing, providing statistically sound decision-making capabilities that decreased decision times by 50%",
  "Created distributed data processing architecture for high-volume, real-time event streams, enabling instant insights through comprehensive monitoring dashboards",
  "Designed ML deployment pipelines with automated testing, monitoring, and failover capabilities, resulting in 99.9% uptime for critical ML services",
)

// Heavywater
#let heavywater_bullets = (
  "Developed advanced document classification system capable of identifying over 300 document types in complex multi-page financial packages with high accuracy",
  "Implemented computer vision and NLP techniques to analyze and extract structured information from unstructured documents, achieving 96% accuracy on complex financial data",
  "Engineered named entity recognition (NER) system for extracting and validating critical information from financial documents, significantly improving data quality and compliance",
  "Designed scalable, serverless data pipelines on AWS for efficient training data collection and automated model retraining, improving model performance while reducing manual effort",
)

// Education bullets
#let temple_bullets = (
  "Specialized in advanced statistical methods and machine learning, with research focus on probabilistic modeling and predictive analytics for complex data structures",
)

#let lehigh_bullets = (
  "Foundation in mathematical modeling, statistical analysis, and computational methods, with coursework in algorithm design and data structures",
)

// Project bullets
#let pocketsize_bullets = (
  "Co-founder and CTO of Pocket Size Fund, an open source quantitative hedge fund leveraging ML models for automated trading strategies and portfolio optimization",
)