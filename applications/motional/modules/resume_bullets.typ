// Bullet points for work experience (customizable per job)

// URBN
#let urbn_bullets = (
  "Led migration from Airflow to Flyte, designing and implementing robust data processing pipelines that improved ETL workflow orchestration and handled terabytes of data efficiently",
  "Designed and implemented AWS-based ETL infrastructure utilizing EKS for containerization, Lambda for serverless processing, and S3 for data storage, establishing a scalable data platform",
  "Developed Python-based distributed processing systems for high-volume data transformation, creating self-service interfaces that enabled stakeholders to access and utilize data independently",
  "Established CI/CD pipelines and quality assurance practices by implementing Pandera, Pydantic, and Cucumber tests for data validation, ensuring data quality at scale across the organization",
  "Collaborated with cross-functional teams to implement data engineering best practices and accelerate deployment processes, communicating complex technical concepts to business stakeholders",
)

// Pepsico Head ML Engineering
#let pepsico_head_bullets = (
  "Led and provided mentorship to a cross-functional team of 8 data engineers and scientists, managing project timelines and roadmap deliverables while fostering professional development and technical growth",
  "Designed and implemented large-scale data processing architecture for petabyte-scale analytics, utilizing AWS ETL technologies and distributed systems principles to process and transform complex datasets",
  "Collaborated with stakeholders to align data platform capabilities with business objectives, developing project timelines and coordinating product design and execution across multiple functional areas",
  "Managed end-to-end delivery of self-service data pipeline interfaces that enabled non-technical users to access and transform data, increasing organizational data utilization by 200%",
  "Championed high-quality system design and code reviews for ETL processes and data transformations, establishing best practices for distributed system development in a fast-paced environment",
)

// Pepsico Principal Data Scientist
#let pepsico_principal_bullets = (
  "Architected robust data pipeline infrastructure using Python and AWS services, implementing distributed processing systems that standardized ETL workflows from ingestion to transformation, reducing pipeline development time by 50%",
  "Designed and developed microservices architecture for data processing using EKS (Kubernetes) and containerization, enabling seamless scaling for variable processing loads and ensuring system reliability",
  "Implemented Lambda-based serverless ETL processes for batch and real-time data transformation, processing terabytes of data while optimizing for cost and performance in a distributed environment",
  "Created self-service data interfaces that allowed business users to configure and run ETL processes without engineering assistance, significantly reducing development bottlenecks",
  "Optimized AWS infrastructure for large-scale data processing, implementing cost-effective solutions that reduced monthly cloud expenditure by over $10k while maintaining performance",
  "Led implementation of comprehensive monitoring solutions for data pipelines using CloudWatch and custom metrics, ensuring data quality and system reliability at scale",
  "Developed Python libraries and frameworks for standardized data ingestion and transformation, creating reusable components that accelerated development cycles",
  "Collaborated with cross-functional teams to define data models and transformation requirements, effectively communicating technical concepts to non-technical stakeholders",
)

// Penn Interactive
#let penn_interactive_bullets = (
  "Designed high-volume distributed data processing systems handling over 500TB of user event data daily, implementing fault-tolerant architecture with continuous data flow monitoring",
  "Built infrastructure monitoring solutions using DataDog to track ETL pipeline performance, system health, and data quality, enabling proactive issue resolution and minimizing downtime",
  "Developed microservices architecture for data transformation and processing using Kubernetes (EKS) for container orchestration, ensuring scalability and isolation of data pipeline components",
  "Implemented continuous delivery pipelines for data processing code, automating testing and deployment processes to enable rapid iteration in a fast-paced environment",
  "Created data extraction and transformation services with Python, processing unstructured data from diverse sources into standardized formats for downstream consumption",
  "Led technical communication between data engineering and analytics teams, establishing clear documentation and interfaces for data access that improved cross-team collaboration",
)

// Heavywater
#let heavywater_bullets = (
  "Designed and implemented ETL pipelines for extracting, transforming, and loading data from unstructured documents, processing terabytes of complex financial data for downstream analysis",
  "Developed Python-based data processing system that extracted structured information from unstructured document sources, implementing distributed processing to handle high-volume document ingestion",
  "Created serverless data pipelines using AWS Lambda and S3 for efficient data transformation, enabling automatic scaling based on processing load while maintaining high throughput",
  "Implemented comprehensive data quality validation in ETL workflows, ensuring accuracy and consistency of extracted information through automated checks and verification procedures",
)

// Education bullets
#let temple_bullets = (
  "Advanced study in data systems architecture, distributed computing, Python programming, and scalable data processing techniques applicable to large-scale distributed data platforms",
)

#let lehigh_bullets = (
  "Computer Science curriculum including data structures, algorithms, and system design fundamentals with particular focus on distributed systems and scalable architectures",
)

// Project bullets
#let pocketsize_bullets = (
  "Co-founder and CTO of Pocket Size Fund, designing and implementing data processing pipelines and ETL systems for high-frequency financial data analysis using AWS cloud infrastructure and Python",
)